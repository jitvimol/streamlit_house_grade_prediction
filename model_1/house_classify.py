# -*- coding: utf-8 -*-
"""house_classify.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12N1QOEaObhJB534YJcbpdAEDB4BcV9BM

#Install Essential Framework
"""

! pip install -qq fastai --upgrade

! pip install -qq kaggle

! mkdir ~/.kaggle

!gdown --id 1Wq_i3cMpUTHslUP1plzL76SeK66gLLXE

! cp kaggle.json ~/.kaggle/

! chmod 600 ~/.kaggle/kaggle.json

! kaggle competitions download -c super-ai-engineer-2021-house-grade-classification

!unzip -qq /content/super-ai-engineer-2021-house-grade-classification.zip

!pip install efficientnet_pytorch

!git clone https://github.com/d-li14/efficientnetv2.pytorch

!pip install tensorflow==2.8.0
!pip install tensorflow-addons
!pip install focal-loss

!pip install fastai wwf timm -q --upgrade

"""#Import library"""

#importing required modules
import gdown
import zipfile
import numpy as np
from glob import glob
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
from torchsummary import summary
from torchvision import datasets, transforms as T
import os
import torch.optim as optim
from PIL import ImageFile
from sklearn.metrics import accuracy_score
import imageio
from tqdm import tqdm

import cv2
from google.colab.patches import cv2_imshow
from PIL import Image
import math
import pandas as pd

import fastai
from fastai.vision.all import *
from fastai.vision.augment import *
from fastai.metrics import *

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tqdm import tqdm
import tensorflow as tf
#import tensorflow_addons as tfa

"""##Check CUDA"""

#Checking the availability of a GPU
use_cuda = torch.cuda.is_available()
print(use_cuda)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
#device = 'cpu'
print(device)

"""#EDA"""

df = pd.read_csv('train.csv')
df.columns = ['fname', 'labels']
df

df.labels.value_counts().sum()

df.groupby('labels').count()

df.groupby('labels').count().mean()

plt.hist(x=df['labels'])

"""###Balancing data"""

#from torch.utils.data.sampler import WeightedRandomSampler
#
#def sampler_(dataset):
#    dataset_counts = df.groupby('labels').count().fname.to_list()
#    num_samples = sum(dataset_counts)
#    labels = [tag for tag in dataset.labels]
#
#    class_weights = [num_samples/dataset_counts[i] for i in range(len(dataset_counts))]
#    weights = [class_weights[labels[i]] for i in range(num_samples)]
#    sampler = WeightedRandomSampler(torch.DoubleTensor(weights), 3600) #int(num_samples))
#    return sampler

#Create weight of each Labels

def weights_(dataset=df, n_sample=3000):
    dataset_counts = dataset.groupby('labels').count().fname.to_list() #n_label
    num_samples = sum(dataset_counts) #n_samples
    labels = [tag for tag in dataset.labels]

    class_weights = [num_samples/(len(dataset_counts)*dataset_counts[i]) for i in range(len(dataset_counts))]
    weights = [class_weights[labels[i]] for i in range(num_samples)]
    balance_df = dataset.sample(n_sample, weights=weights, replace=True)

    return balance_df

#weighted sampling
#try changing n_sample

balance_df = weights_(df,7200)

balance_df

balance_df.groupby('labels').count()

plt.hist(x=balance_df['labels'])

"""###Data Augmentation"""

tfms = [FlipItem(p=0.75), Zoom(max_zoom=1.1, p = 0.25)]





"""#Train"""

path = '/content/train'
dls = ImageDataLoaders.from_df(balance_df, path,folder=None,  device = 'cuda', item_tfms=Resize(240, 240), batch_tfms=[FlipItem(p=0.75), Zoom(max_zoom=1.1, p = 0.25)])

dls.show_batch()

from efficientnet_pytorch import EfficientNet

effnetb1 =  EfficientNet.from_pretrained('efficientnet-b1', num_classes=6)


learn = Learner(dls, 
                    effnetb1, 
                    metrics=[F1Score(average='macro'),error_rate])
# learn.lr_find()

#lr_range = learn.lr_find()

learn.fine_tune(30, 1e-3)

learn.show_results(max_n=100)

preds = learn.get_preds(with_decoded=True)

from sklearn.metrics import f1_score, ConfusionMatrixDisplay, classification_report

ConfusionMatrixDisplay.from_predictions(preds[1], preds[2])
plt.show()
f1_score(preds[1], preds[2], average='macro')

interp = ClassificationInterpretation.from_learner(learn)
interp.plot_confusion_matrix()

interp.plot_top_losses(9, figsize=(15,11))

print(classification_report(preds[1], preds[2]))

"""#Prediction"""

fnames = get_image_files('/content/test')

root_dir = '/content/test'
prediction = {'Id': [], 'Predicted': []}
for idx, file in tqdm(enumerate(os.listdir(root_dir))):

    id = file.replace('.jpg', '')

    id_name = id
    prediction['Id'].append(id_name)
    prediction['Predicted'].append(learn.predict(fnames[idx])[0])

"""#Submission"""

df_submit = pd.DataFrame(prediction)
df_submit

df_submit.to_csv('submission.csv', index = False)

df_sample = pd.read_csv('/content/sample_submission.csv')
# df_sample.Predicted = 0
df_sample

df_final = df_sample.merge(df_submit, on='Id', how='left')
df_final.Predicted_x = df_final.Predicted_y
df_final = df_final.drop(columns = ['Predicted_y'])
df_final = df_final.fillna('0')
df_final.columns = ['Id', 'Predicted']
df_final

df_final.Predicted.value_counts()

df_final[df_final['Id'] == '7a45401e']

df_final.to_csv('ready_submission.csv', index = False)

"""###Save model"""

learn.save('/content/effnet_bal7200_aug_30ep_lr3')

learn.export(fname='/content/effnet_bal7200_aug_30ep_lr3.pkl')

!cp /content/effnet_bal7200_aug_30ep_lr3.pth /content/drive/MyDrive
!cp /content/effnet_bal7200_aug_30ep_lr3.pkl /content/drive/MyDrive
!cp /content/ready_submission.csv /content/drive/MyDrive

"""## upload to kaggle"""

#!kaggle competitions submit -c super-ai-engineer-2021-house-grade-classification -f ready_submission.csv -m "First Try"

